{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "079e2e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neuroCombat in /home/diego/anaconda3/lib/python3.11/site-packages (0.2.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install neuroCombat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5c48fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Cargando Metadatos de Sujetos ---\n",
      "Metadatos cargados para 434 sujetos.\n",
      "Sitios identificados: ['002', '003', '005', '006', '010', '011', '012', '013', '014', '018', '019', '021', '022', '024', '027', '031', '032', '035', '037', '041', '053', '057', '068', '082', '094', '098', '099', '100', '109', '114', '116', '123', '126', '127', '128', '129', '130', '131', '135', '136', '141', '168', '177', '301', '305', '941']\n",
      "Columnas disponibles: ['SubjectID', 'Phase', 'Sex', 'ResearchGroup', 'Visit', 'ArchiveDate', 'StudyDate', 'Age', 'Modality', 'Description', 'ImagingProtocol', 'ImageID', 'PTEDUCAT', 'CDRSB', 'MMSE', 'DIGITSCOR', 'MOCA', 'Ventricles', 'Hippocampus', 'WholeBrain', 'MidTemp', 'ABETA', 'TAU', 'PTAU', 'SiteID']\n",
      "Se encontraron archivos .mat para 434 sujetos.\n",
      "ADVERTENCIA: No se pudieron cargar las coordenadas de ROIs. Error: \"None of [Index(['x', 'y', 'z'], dtype='object')] are in the [columns]\"\n",
      "Los gráficos cerebrales 3D no se generarán.\n",
      "\n",
      "--- 3. Procesando Sujeto por Sujeto (QC y Cálculo de Conectividad) ---\n",
      "Procesando: 002_S_0295...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 002_S_0413...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 002_S_0685...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 002_S_0729...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 002_S_1155...  13 TPs eliminados. TPs restantes: 184\n",
      "Procesando: 002_S_2010...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 002_S_2043...  8 TPs eliminados. TPs restantes: 132\n",
      "Procesando: 002_S_2073...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 002_S_4171...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 002_S_4213...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 002_S_4219...  7 TPs eliminados. TPs restantes: 133\n",
      "Procesando: 002_S_4229...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 002_S_4237...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 002_S_4251...  7 TPs eliminados. TPs restantes: 133\n",
      "Procesando: 002_S_4262...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 002_S_4264...  8 TPs eliminados. TPs restantes: 132\n",
      "Procesando: 002_S_4270...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 002_S_4473...  0 TPs eliminados. TPs restantes: 197\n",
      "Procesando: 002_S_4654...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 002_S_4799...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 003_S_0908...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 003_S_1074...  13 TPs eliminados. TPs restantes: 184\n",
      "Procesando: 003_S_1122...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 003_S_4354...  27 TPs eliminados. TPs restantes: 170\n",
      "Procesando: 003_S_6258...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 003_S_6264...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 003_S_6268...  12 TPs eliminados. TPs restantes: 185\n",
      "Procesando: 003_S_6432...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 003_S_6606...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 003_S_6678...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 003_S_6833...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 003_S_6954...  1 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 005_S_4185...  10 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 006_S_0498...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 006_S_0731...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 006_S_4150...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 006_S_4153...  0 TPs eliminados. TPs restantes: 140\n",
      "Procesando: 006_S_4192...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 006_S_4346...  12 TPs eliminados. TPs restantes: 128\n",
      "Procesando: 006_S_4357...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 006_S_4363...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 006_S_4449...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 006_S_4485...  8 TPs eliminados. TPs restantes: 132\n",
      "Procesando: 006_S_4546...  9 TPs eliminados. TPs restantes: 131\n",
      "Procesando: 006_S_4679...  8 TPs eliminados. TPs restantes: 132\n",
      "Procesando: 006_S_4713...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 006_S_4867...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 006_S_4960...  12 TPs eliminados. TPs restantes: 128\n",
      "Procesando: 006_S_6209...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 006_S_6234...  0 TPs eliminados. TPs restantes: 197\n",
      "Procesando: 006_S_6243...  10 TPs eliminados. TPs restantes: 187\n",
      "Procesando: 006_S_6252...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 006_S_6291...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 006_S_6375...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 006_S_6441...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 006_S_6610...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 006_S_6651...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 006_S_6657...  0 TPs eliminados. TPs restantes: 197\n",
      "Procesando: 006_S_6672...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 006_S_6674...  16 TPs eliminados. TPs restantes: 181\n",
      "Procesando: 006_S_6677...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 006_S_6682...  15 TPs eliminados. TPs restantes: 182\n",
      "Procesando: 006_S_6689...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 006_S_6696...  0 TPs eliminados. TPs restantes: 197\n",
      "Procesando: 006_S_6770...  8 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 010_S_4135...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 010_S_4442...  11 TPs eliminados. TPs restantes: 129\n",
      "Procesando: 010_S_5163...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 011_S_4547...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 011_S_4827...  8 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 011_S_4893...  8 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 011_S_6303...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 011_S_6618...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 012_S_4026...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 012_S_4094...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 012_S_4128...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 012_S_4188...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 012_S_4643...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 012_S_4849...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 012_S_4987...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 012_S_6073...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 012_S_6503...  11 TPs eliminados. TPs restantes: 186\n",
      "Procesando: 012_S_6760...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 013_S_1186...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 013_S_2324...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 013_S_2389...  9 TPs eliminados. TPs restantes: 131\n",
      "Procesando: 013_S_4236...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 013_S_4268...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 013_S_4395...  7 TPs eliminados. TPs restantes: 133\n",
      "Procesando: 013_S_4580...  8 TPs eliminados. TPs restantes: 132\n",
      "Procesando: 013_S_4595...  11 TPs eliminados. TPs restantes: 129\n",
      "Procesando: 013_S_4616...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 013_S_4731...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 013_S_4768...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 013_S_4791...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 013_S_4917...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 013_S_4985...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 013_S_5071...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 013_S_6206...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 013_S_6725...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 013_S_6768...  17 TPs eliminados. TPs restantes: 180\n",
      "Procesando: 013_S_6970...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 013_S_6975...  12 TPs eliminados. TPs restantes: 185\n",
      "Procesando: 013_S_7097...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 014_S_2308...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 014_S_6087...  8 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 014_S_6765...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 014_S_6944...  0 TPs eliminados. TPs restantes: 197\n",
      "Procesando: 018_S_2133...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 018_S_2155...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 018_S_2180...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 018_S_4257...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 018_S_4313...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 018_S_4349...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 018_S_4400...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 018_S_4597...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 018_S_4696...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 018_S_4733...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 018_S_4809...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 018_S_4868...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 018_S_4889...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 018_S_5074...  6 TPs eliminados. TPs restantes: 134\n",
      "Procesando: 018_S_5240...  0 TPs eliminados. TPs restantes: 140\n",
      "Procesando: 018_S_6207...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 018_S_6351...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 018_S_6414...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 019_S_4252...  9 TPs eliminados. TPs restantes: 131\n",
      "Procesando: 019_S_4285...  8 TPs eliminados. TPs restantes: 132\n",
      "Procesando: 019_S_4293...  9 TPs eliminados. TPs restantes: 131\n",
      "Procesando: 019_S_4367...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 019_S_4477...  7 TPs eliminados. TPs restantes: 133\n",
      "Procesando: 019_S_4548...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 019_S_4549...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 019_S_4680...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 019_S_4835...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 019_S_5012...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 019_S_5019...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 019_S_6186...  10 TPs eliminados. TPs restantes: 187\n",
      "Procesando: 019_S_6315...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 019_S_6483...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 019_S_6573...  11 TPs eliminados. TPs restantes: 186\n",
      "Procesando: 019_S_6585...  11 TPs eliminados. TPs restantes: 186\n",
      "Procesando: 019_S_6630...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 019_S_6635...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 019_S_6668...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 019_S_6712...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 019_S_6757...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 019_S_7016...  0 TPs eliminados. TPs restantes: 197\n",
      "Procesando: 021_S_4659...  10 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 021_S_4744...  11 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 022_S_2263...  17 TPs eliminados. TPs restantes: 180\n",
      "Procesando: 022_S_2379...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 022_S_6013...  11 TPs eliminados. TPs restantes: 186\n",
      "Procesando: 022_S_6280...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 022_S_6716...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 024_S_4674...  0 TPs eliminados. TPs restantes: 197\n",
      "Procesando: 024_S_6033...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 027_S_2219...  7 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 027_S_2245...  7 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 027_S_4869...  5 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 027_S_4919...  5 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 027_S_6648...  6 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 027_S_6733...  4 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 027_S_6849...  21 TPs eliminados. TPs restantes: 179\n",
      "Procesando: 027_S_6965...  10 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 031_S_2018...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 031_S_2022...  6 TPs eliminados. TPs restantes: 134\n",
      "Procesando: 031_S_2233...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 031_S_4005...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 031_S_4024...  11 TPs eliminados. TPs restantes: 129\n",
      "Procesando: 031_S_4029...  6 TPs eliminados. TPs restantes: 134\n",
      "Procesando: 031_S_4032...  6 TPs eliminados. TPs restantes: 134\n",
      "Procesando: 031_S_4042...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 031_S_4149...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 031_S_4194...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 031_S_4203...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 031_S_4218...  6 TPs eliminados. TPs restantes: 134\n",
      "Procesando: 031_S_4474...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 031_S_4476...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 031_S_4496...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 031_S_4590...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 031_S_4721...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 031_S_4947...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 031_S_6715...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 032_S_2119...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 032_S_6055...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 032_S_6600...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 032_S_6602...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 032_S_6700...  11 TPs eliminados. TPs restantes: 186\n",
      "Procesando: 032_S_6804...  8 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 032_S_6855...  16 TPs eliminados. TPs restantes: 181\n",
      "Procesando: 035_S_4114...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 035_S_4414...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 035_S_6380...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 035_S_6480...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 035_S_6641...  1 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 035_S_6650...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 035_S_6660...  1 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 035_S_6947...  11 TPs eliminados. TPs restantes: 186\n",
      "Procesando: 035_S_7000...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 035_S_7001...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 035_S_7021...  37 TPs eliminados. TPs restantes: 160\n",
      "Procesando: 035_S_7049...  11 TPs eliminados. TPs restantes: 186\n",
      "Procesando: 035_S_7073...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 035_S_7105...  0 TPs eliminados. TPs restantes: 197\n",
      "Procesando: 035_S_7120...  11 TPs eliminados. TPs restantes: 186\n",
      "Procesando: 035_S_7121...  0 TPs eliminados. TPs restantes: 197\n",
      "Procesando: 037_S_0150...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 037_S_0377...  20 TPs eliminados. TPs restantes: 177\n",
      "Procesando: 037_S_4030...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 037_S_4214...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 037_S_4302...  11 TPs eliminados. TPs restantes: 186\n",
      "Procesando: 037_S_4706...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 041_S_4051...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 041_S_4143...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 041_S_4271...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 041_S_4510...  8 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 041_S_4513...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 041_S_4874...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 041_S_4876...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 041_S_4974...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 053_S_0919...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 053_S_2357...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 053_S_2396...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 053_S_4557...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 053_S_4578...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 053_S_4661...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 053_S_4813...  9 TPs eliminados. TPs restantes: 131\n",
      "Procesando: 053_S_5070...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 053_S_5208...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 053_S_6598...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 053_S_6861...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 053_S_7086...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 053_S_7109...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 057_S_6746...  10 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 057_S_6869...  13 TPs eliminados. TPs restantes: 187\n",
      "Procesando: 068_S_2184...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 068_S_2187...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 068_S_2315...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 068_S_4061...  8 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 068_S_4067...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 068_S_4332...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 068_S_4431...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 082_S_2121...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 082_S_6690...  8 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 094_S_2201...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 094_S_2238...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 098_S_6601...  10 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 098_S_6655...  7 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 098_S_6658...  4 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 099_S_2146...  8 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 100_S_0069...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 100_S_1286...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 100_S_2351...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 100_S_4469...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 100_S_4511...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 100_S_4512...  11 TPs eliminados. TPs restantes: 129\n",
      "Procesando: 100_S_4556...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 100_S_4884...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 100_S_4970...  7 TPs eliminados. TPs restantes: 133\n",
      "Procesando: 100_S_5106...  8 TPs eliminados. TPs restantes: 132\n",
      "Procesando: 100_S_5246...  7 TPs eliminados. TPs restantes: 133\n",
      "Procesando: 100_S_6164...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 100_S_6273...  8 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 100_S_6308...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 100_S_6349...  10 TPs eliminados. TPs restantes: 187\n",
      "Procesando: 100_S_6493...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 100_S_6578...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 100_S_6713...  10 TPs eliminados. TPs restantes: 187\n",
      "Procesando: 109_S_4380...  14 TPs eliminados. TPs restantes: 183\n",
      "Procesando: 114_S_2392...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 114_S_4404...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 114_S_5047...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 114_S_6347...  10 TPs eliminados. TPs restantes: 187\n",
      "Procesando: 114_S_6368...  13 TPs eliminados. TPs restantes: 184\n",
      "Procesando: 114_S_6595...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 116_S_4199...  10 TPs eliminados. TPs restantes: 187\n",
      "Procesando: 116_S_6100...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 116_S_6543...  14 TPs eliminados. TPs restantes: 183\n",
      "Procesando: 123_S_0072...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 123_S_0106...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 123_S_0298...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 123_S_1300...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 123_S_4127...  0 TPs eliminados. TPs restantes: 197\n",
      "Procesando: 123_S_4170...  1 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 123_S_6118...  8 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 123_S_6825...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 123_S_6888...  11 TPs eliminados. TPs restantes: 186\n",
      "Procesando: 123_S_6891...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 126_S_4507...  13 TPs eliminados. TPs restantes: 187\n",
      "Procesando: 126_S_4514...  8 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 126_S_4891...  7 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 126_S_4896...  2 TPs eliminados. TPs restantes: 198\n",
      "Procesando: 126_S_6683...  19 TPs eliminados. TPs restantes: 181\n",
      "Procesando: 126_S_6721...  12 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 127_S_2234...  7 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 127_S_4197...  0 TPs eliminados. TPs restantes: 200\n",
      "Procesando: 127_S_4210...  6 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 127_S_4301...  10 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 127_S_4765...  2 TPs eliminados. TPs restantes: 198\n",
      "Procesando: 127_S_4928...  18 TPs eliminados. TPs restantes: 182\n",
      "Procesando: 127_S_6433...  8 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 127_S_6549...  8 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 128_S_2036...  7 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 128_S_2123...  9 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 128_S_2130...  2 TPs eliminados. TPs restantes: 198\n",
      "Procesando: 128_S_2220...  11 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 128_S_4842...  8 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 129_S_2332...  7 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 129_S_6763...  5 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 129_S_6784...  7 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 130_S_0969...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 130_S_2391...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 130_S_2402...  6 TPs eliminados. TPs restantes: 134\n",
      "Procesando: 130_S_2403...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 130_S_4294...  8 TPs eliminados. TPs restantes: 132\n",
      "Procesando: 130_S_4343...  6 TPs eliminados. TPs restantes: 134\n",
      "Procesando: 130_S_4352...  6 TPs eliminados. TPs restantes: 134\n",
      "Procesando: 130_S_4405...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 130_S_4415...  7 TPs eliminados. TPs restantes: 133\n",
      "Procesando: 130_S_4417...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 130_S_4468...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 130_S_4542...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 130_S_4589...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 130_S_4605...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 130_S_4641...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 130_S_4660...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 130_S_4730...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 130_S_4817...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 130_S_4883...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 130_S_4925...  7 TPs eliminados. TPs restantes: 133\n",
      "Procesando: 130_S_4971...  9 TPs eliminados. TPs restantes: 131\n",
      "Procesando: 130_S_4982...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 130_S_4984...  7 TPs eliminados. TPs restantes: 133\n",
      "Procesando: 130_S_4990...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 130_S_4997...  2 TPs eliminados. TPs restantes: 138\n",
      "Procesando: 130_S_5006...  6 TPs eliminados. TPs restantes: 134\n",
      "Procesando: 130_S_5059...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 130_S_5231...  9 TPs eliminados. TPs restantes: 131\n",
      "Procesando: 130_S_6019...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 130_S_6027...  8 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 130_S_6035...  12 TPs eliminados. TPs restantes: 185\n",
      "Procesando: 130_S_6037...  12 TPs eliminados. TPs restantes: 185\n",
      "Procesando: 130_S_6043...  10 TPs eliminados. TPs restantes: 187\n",
      "Procesando: 130_S_6047...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 130_S_6072...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 130_S_6105...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 130_S_6111...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 130_S_6137...  15 TPs eliminados. TPs restantes: 182\n",
      "Procesando: 130_S_6161...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 130_S_6319...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 130_S_6361...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 130_S_6372...  0 TPs eliminados. TPs restantes: 197\n",
      "Procesando: 130_S_6388...  1 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 130_S_6390...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 130_S_6391...  14 TPs eliminados. TPs restantes: 183\n",
      "Procesando: 130_S_6469...  10 TPs eliminados. TPs restantes: 187\n",
      "Procesando: 130_S_6558...  1 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 130_S_6604...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 130_S_6611...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 130_S_6612...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 130_S_6639...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 130_S_6646...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 130_S_6647...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 130_S_6823...  0 TPs eliminados. TPs restantes: 197\n",
      "Procesando: 131_S_0384...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 131_S_5138...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 131_S_6143...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 131_S_6616...  8 TPs eliminados. TPs restantes: 189\n",
      "Procesando: 131_S_7032...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 135_S_4356...  6 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 135_S_4489...  7 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 135_S_4722...  5 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 135_S_4723...  2 TPs eliminados. TPs restantes: 198\n",
      "Procesando: 135_S_6284...  8 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 135_S_6389...  7 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 135_S_6545...  10 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 135_S_6687...  3 TPs eliminados. TPs restantes: 197\n",
      "Procesando: 135_S_6840...  8 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 135_S_7003...  13 TPs eliminados. TPs restantes: 187\n",
      "Procesando: 136_S_4269...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 136_S_4408...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 136_S_4433...  1 TPs eliminados. TPs restantes: 139\n",
      "Procesando: 136_S_4517...  5 TPs eliminados. TPs restantes: 135\n",
      "Procesando: 136_S_4726...  6 TPs eliminados. TPs restantes: 134\n",
      "Procesando: 136_S_4727...  6 TPs eliminados. TPs restantes: 134\n",
      "Procesando: 136_S_4836...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 136_S_4848...  3 TPs eliminados. TPs restantes: 137\n",
      "Procesando: 136_S_4932...  6 TPs eliminados. TPs restantes: 134\n",
      "Procesando: 136_S_4956...  4 TPs eliminados. TPs restantes: 136\n",
      "Procesando: 136_S_4993...  0 TPs eliminados. TPs restantes: 140\n",
      "Procesando: 141_S_2333...  10 TPs eliminados. TPs restantes: 187\n",
      "Procesando: 141_S_4160...  1 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 168_S_6142...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 168_S_6735...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 168_S_6754...  1 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 168_S_6827...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 168_S_6828...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 168_S_6843...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 168_S_6921...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 168_S_6938...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 177_S_6328...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 177_S_6335...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 177_S_6408...  1 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 177_S_6409...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 177_S_6420...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 177_S_6448...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 301_S_6056...  10 TPs eliminados. TPs restantes: 187\n",
      "Procesando: 301_S_6224...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 301_S_6297...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 301_S_6326...  6 TPs eliminados. TPs restantes: 191\n",
      "Procesando: 301_S_6501...  12 TPs eliminados. TPs restantes: 185\n",
      "Procesando: 301_S_6508...  5 TPs eliminados. TPs restantes: 192\n",
      "Procesando: 301_S_6592...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 301_S_6615...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 301_S_6698...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 301_S_6777...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 301_S_6811...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 305_S_6157...  1 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 305_S_6188...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 305_S_6313...  14 TPs eliminados. TPs restantes: 183\n",
      "Procesando: 305_S_6438...  1 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 305_S_6498...  12 TPs eliminados. TPs restantes: 185\n",
      "Procesando: 305_S_6742...  16 TPs eliminados. TPs restantes: 181\n",
      "Procesando: 305_S_6744...  7 TPs eliminados. TPs restantes: 190\n",
      "Procesando: 305_S_6810...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 305_S_6845...  1 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 305_S_6850...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 305_S_6871...  3 TPs eliminados. TPs restantes: 194\n",
      "Procesando: 305_S_6877...  2 TPs eliminados. TPs restantes: 195\n",
      "Procesando: 305_S_6881...  4 TPs eliminados. TPs restantes: 193\n",
      "Procesando: 305_S_6899...  9 TPs eliminados. TPs restantes: 188\n",
      "Procesando: 941_S_4036...  1 TPs eliminados. TPs restantes: 196\n",
      "Procesando: 941_S_4187...  6 TPs eliminados. TPs restantes: 191\n",
      "\n",
      "Procesamiento finalizado para 434 sujetos.\n",
      "Reporte de QC guardado en: tesis_pipeline_outputs_v5.3/final_qc_summary.csv\n",
      "\n",
      "--- 4. Generando Visualizaciones y Reportes Finales ---\n",
      "Generando gráficos de QC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5. Armonizando Datos de Conectividad con ComBat ---\n",
      "ADVERTENCIA: Excluyendo 3 sitios con < 2 sujetos para ComBat: ['109', '099', '005']\n",
      "Sujetos retenidos para armonización: 431\n",
      "Ejecutando la armonización con ComBat en la muestra filtrada...\n",
      "[neuroCombat] Creating design matrix\n",
      "[neuroCombat] Standardizing data across features\n",
      "[neuroCombat] Fitting L/S model and finding priors\n",
      "[neuroCombat] Finding parametric adjustments\n",
      "[neuroCombat] Final adjustment of data\n",
      "Armonización con ComBat completada con éxito.\n",
      "Generando gráfico del efecto de ComBat...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando conectoma promedio y generando visualizaciones finales...\n",
      "Conectoma promedio calculado. Min: -0.0044, Max: 0.9150\n",
      "Generando gráficos de conectividad...\n",
      "No se generará el conectoma 3D por falta de coordenadas.\n",
      "Generando gráficos de conectividad dinámica...\n",
      "\n",
      "--- ¡Pipeline Finalizado! ---\n",
      "Resultados y gráficos guardados en: tesis_pipeline_outputs_v5.3\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================\n",
    "# PIPELINE DE ANÁLISIS DE CONECTIVIDAD FUNCIONAL PARA TESIS DOCTORAL (v5.3)\n",
    "#\n",
    "# Autor: Dr. Diego [Tu Apellido] (Adaptado y expandido por Gemini)\n",
    "# Fecha: 19 de junio de 2025\n",
    "#\n",
    "# Descripción:\n",
    "# Este script implementa un pipeline completo para el análisis de datos de rs-fMRI.\n",
    "#\n",
    "# Cambios v5.3:\n",
    "# - ELIMINADO: Se comentó la generación de `fig_mean_connectome_matrix.png`\n",
    "#   para evitar un gráfico vacío o de ceros.\n",
    "# - CORREGIDO: La edad de los sujetos ahora se lee desde la columna 'Age' en\n",
    "#   SubjectsData_Schaefer2018.csv, eliminando la data ficticia.\n",
    "# - MEJORADO: La creación del dataframe de covariables (`covariates`) es más\n",
    "#   limpia y robusta.\n",
    "# - CORREGIDO: El error de guardado de `fig_mean_connectome_matrix.png` ha sido\n",
    "#   solucionado. Se gestiona la figura directamente desde nilearn.\n",
    "# - AÑADIDO: Nuevas visualizaciones de QC para analizar la distribución del\n",
    "#   scrubbing (Histograma y Violin Plot por Sitio).\n",
    "# - AÑADIDO: Gráfico de densidad para visualizar el efecto de la armonización ComBat.\n",
    "# - MEJORADO: Prints más detallados durante la ejecución para un seguimiento claro.\n",
    "# - MEJORADO: Estructura de funciones de visualización para mayor claridad.\n",
    "# =================================================================================\n",
    "\n",
    "# ---------- 0. SETUP E IMPORTACIONES ----------\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore, median_abs_deviation\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "\n",
    "# --- Librerías especializadas (requieren instalación) ---\n",
    "# pip install nilearn neurocombat-sklearn hmmlearn\n",
    "from nilearn import plotting as nilearn_plotting\n",
    "from nilearn.connectome import sym_matrix_to_vec, vec_to_sym_matrix\n",
    "try:\n",
    "    from neuroCombat import neuroCombat\n",
    "    NEUROCOMBAT_INSTALLED = True\n",
    "except ImportError:\n",
    "    NEUROCOMBAT_INSTALLED = False\n",
    "\n",
    "# --- Ignorar advertencias para reportes más limpios ---\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# ---------- 1. CONFIGURACIÓN Y CARGA DE DATOS ----------\n",
    "\n",
    "# --- Parámetros de Configuración ---\n",
    "ROI_DIR = Path('./ROISignals_Schaefer2018_100Parcels_17Networks_NiftiPreprocessedAllBatchesNorm')\n",
    "CSV_PATH = Path('SubjectsData_Schaefer2018.csv')\n",
    "SCHAEFER_COORDS_PATH = Path('Schaefer2018_100Parcels_7Networks_order_FSLMNI152_2mm.Centroid_RAS.csv')\n",
    "\n",
    "EXPORT_DIR = Path('./tesis_pipeline_outputs_v5.3') # Directorio actualizado\n",
    "EXPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Parámetros del Atlas y QC\n",
    "N_ROIS = 100\n",
    "SUBJECT_ID_COL = 'SubjectID'\n",
    "TR = 3.0\n",
    "Z_THRESHOLD_UNIV = 3.0\n",
    "\n",
    "# Parámetros de QC Avanzado\n",
    "PCA_N_COMPONENTS = 10\n",
    "LEVERAGE_MAD_FACTOR = 5.0\n",
    "\n",
    "# Parámetros de Conectividad Dinámica\n",
    "SW_WINDOW_SIZE_SEC = 30\n",
    "SW_WINDOW_SIZE_TR = int(SW_WINDOW_SIZE_SEC / TR)\n",
    "SW_STEP_TR = 1\n",
    "N_CONNECTIVITY_STATES = 5\n",
    "\n",
    "# --- Carga de Metadatos ---\n",
    "print(\"--- 1. Cargando Metadatos de Sujetos ---\")\n",
    "try:\n",
    "    meta_df = pd.read_csv(CSV_PATH)\n",
    "    meta_df[SUBJECT_ID_COL] = meta_df[SUBJECT_ID_COL].astype(str).str.strip()\n",
    "    meta_df['SiteID'] = meta_df[SUBJECT_ID_COL].apply(lambda x: x.split('_')[0])\n",
    "    \n",
    "    print(f\"Metadatos cargados para {len(meta_df)} sujetos.\")\n",
    "    print(f\"Sitios identificados: {meta_df['SiteID'].unique().tolist()}\")\n",
    "    print(f\"Columnas disponibles: {meta_df.columns.tolist()}\") # Para verificar que 'Age' está\n",
    "\n",
    "    meta_df['MatPath'] = meta_df[SUBJECT_ID_COL].apply(lambda sid: ROI_DIR / f'ROISignals_{sid}.mat')\n",
    "    meta_df['MatExists'] = meta_df['MatPath'].apply(lambda p: p.exists())\n",
    "    subjects_with_mat = meta_df[meta_df['MatExists']].copy()\n",
    "    print(f\"Se encontraron archivos .mat para {len(subjects_with_mat)} sujetos.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: No se pudieron cargar los metadatos de {CSV_PATH}. Error: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Carga de Coordenadas para Gráficos ---\n",
    "try:\n",
    "    schaefer_coords = pd.read_csv(SCHAEFER_COORDS_PATH)[['x', 'y', 'z']].values\n",
    "    if schaefer_coords.shape != (N_ROIS, 3):\n",
    "        raise ValueError(f\"Las coordenadas deberían tener shape ({N_ROIS}, 3) pero tienen {schaefer_coords.shape}\")\n",
    "    print(f\"Coordenadas de ROIs cargadas exitosamente desde {SCHAEFER_COORDS_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"ADVERTENCIA: No se pudieron cargar las coordenadas de ROIs. Error: {e}\")\n",
    "    print(\"Los gráficos cerebrales 3D no se generarán.\")\n",
    "    schaefer_coords = None\n",
    "\n",
    "# ---------- 2. FUNCIONES DE PROCESAMIENTO Y QC POR SUJETO ----------\n",
    "\n",
    "def load_signals(mat_path: Path):\n",
    "    try:\n",
    "        data = sio.loadmat(str(mat_path))\n",
    "        keys = [k for k in data if isinstance(data[k], np.ndarray) and data[k].ndim == 2]\n",
    "        if not keys: raise ValueError(\"No se encontró ninguna matriz 2D.\")\n",
    "        signals_key = max(keys, key=lambda k: data[k].size)\n",
    "        return np.asarray(data[signals_key], dtype=float)\n",
    "    except Exception as e:\n",
    "        print(f\"  Error cargando {mat_path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "def calculate_pca_leverage_mad(signals: np.ndarray, n_components: int, mad_factor: float):\n",
    "    if signals.size == 0: return np.array([]), np.array([])\n",
    "    \n",
    "    scaled_signals = zscore(signals, axis=0)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    scores = pca.fit_transform(scaled_signals)\n",
    "    leverage = np.sum(scores**2, axis=1)\n",
    "    \n",
    "    median_leverage = np.median(leverage)\n",
    "    mad_leverage = median_abs_deviation(leverage)\n",
    "    \n",
    "    if mad_leverage == 0:\n",
    "        threshold = np.mean(leverage) + 3 * np.std(leverage)\n",
    "    else:\n",
    "        threshold = median_leverage + mad_factor * mad_leverage * 1.4826\n",
    "\n",
    "    outlier_indices = np.where(leverage > threshold)[0]\n",
    "    return leverage, outlier_indices\n",
    "\n",
    "def compute_static_connectome(signals: np.ndarray):\n",
    "    if signals.shape[0] < 2: return np.full((N_ROIS, N_ROIS), np.nan)\n",
    "    conn_matrix = np.corrcoef(signals, rowvar=False)\n",
    "    np.fill_diagonal(conn_matrix, 0)\n",
    "    return conn_matrix\n",
    "\n",
    "def analyze_dynamic_connectivity(signals: np.ndarray, window_size_tr: int, step_tr: int, n_states: int):\n",
    "    n_timepoints, n_rois = signals.shape\n",
    "    \n",
    "    window_vectors = []\n",
    "    for i in range(0, n_timepoints - window_size_tr + 1, step_tr):\n",
    "        window_data = signals[i : i + window_size_tr, :]\n",
    "        if np.any(np.std(window_data, axis=0) == 0): continue\n",
    "        window_conn = np.corrcoef(window_data, rowvar=False)\n",
    "        window_vectors.append(sym_matrix_to_vec(window_conn, discard_diagonal=True))\n",
    "    \n",
    "    if len(window_vectors) < n_states: return None, None, None\n",
    "        \n",
    "    window_vectors = np.array(window_vectors)\n",
    "    kmeans = KMeans(n_clusters=n_states, random_state=42, n_init='auto')\n",
    "    state_sequence = kmeans.fit_predict(window_vectors)\n",
    "    \n",
    "    state_centroids = [np.mean(window_vectors[state_sequence == i], axis=0) for i in range(n_states)]\n",
    "    occupancy_rates = [np.sum(state_sequence == i) / len(state_sequence) for i in range(n_states)]\n",
    "    \n",
    "    return state_sequence, state_centroids, occupancy_rates\n",
    "\n",
    "# ---------- 3. LOOP DE PROCESAMIENTO PRINCIPAL ----------\n",
    "print(\"\\n--- 3. Procesando Sujeto por Sujeto (QC y Cálculo de Conectividad) ---\")\n",
    "all_subject_data = []\n",
    "\n",
    "for idx, row in subjects_with_mat.iterrows():\n",
    "    subject_id = row[SUBJECT_ID_COL]\n",
    "    print(f\"Procesando: {subject_id}...\", end=\"\")\n",
    "    \n",
    "    signals_matrix = load_signals(row['MatPath'])\n",
    "    if signals_matrix is None or signals_matrix.shape[1] != N_ROIS:\n",
    "        print(f\"  --> ADVERTENCIA: Saltando sujeto.\")\n",
    "        continue\n",
    "    \n",
    "    n_timepoints, _ = signals_matrix.shape\n",
    "    \n",
    "    univ_outliers_pct = 100 * np.nansum(np.abs(zscore(signals_matrix, axis=0, nan_policy='omit')) > Z_THRESHOLD_UNIV) / signals_matrix.size\n",
    "    leverage, leverage_outlier_idx = calculate_pca_leverage_mad(signals_matrix, PCA_N_COMPONENTS, LEVERAGE_MAD_FACTOR)\n",
    "    signals_scrubbed = np.delete(signals_matrix, leverage_outlier_idx, axis=0)\n",
    "    print(f\"  {len(leverage_outlier_idx)} TPs eliminados. TPs restantes: {signals_scrubbed.shape[0]}\")\n",
    "    \n",
    "    static_conn_matrix = compute_static_connectome(signals_scrubbed)\n",
    "    \n",
    "    dyn_states, dyn_centroids, dyn_occupancy = None, None, None\n",
    "    if signals_scrubbed.shape[0] > SW_WINDOW_SIZE_TR:\n",
    "        dyn_states, dyn_centroids, dyn_occupancy = analyze_dynamic_connectivity(\n",
    "            signals_scrubbed, SW_WINDOW_SIZE_TR, SW_STEP_TR, N_CONNECTIVITY_STATES\n",
    "        )\n",
    "\n",
    "    all_subject_data.append({\n",
    "        'SubjectID': subject_id, 'SiteID': row['SiteID'],\n",
    "        'TimePoints_Original': n_timepoints,\n",
    "        'TimePoints_PostScrubbing': signals_scrubbed.shape[0],\n",
    "        'UnivOutliersPct': univ_outliers_pct,\n",
    "        'LeverageOutliersCount': len(leverage_outlier_idx),\n",
    "        'HasDynamicConnectivity': dyn_centroids is not None,\n",
    "        'StaticConnectivity': static_conn_matrix,\n",
    "        'DynamicStates_Centroids': dyn_centroids,\n",
    "        'DynamicStates_Sequence': dyn_states,\n",
    "        'DynamicStates_Occupancy': dyn_occupancy,\n",
    "    })\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(all_subject_data)\n",
    "results_df.to_pickle(EXPORT_DIR / \"subject_level_processed_data.pkl\")\n",
    "\n",
    "summary_cols = ['SubjectID', 'SiteID', 'TimePoints_Original', 'TimePoints_PostScrubbing',\n",
    "                'UnivOutliersPct', 'LeverageOutliersCount', 'HasDynamicConnectivity']\n",
    "results_df[summary_cols].to_csv(EXPORT_DIR / \"final_qc_summary.csv\", index=False)\n",
    "print(f\"\\nProcesamiento finalizado para {len(results_df)} sujetos.\")\n",
    "print(f\"Reporte de QC guardado en: {EXPORT_DIR / 'final_qc_summary.csv'}\")\n",
    "\n",
    "\n",
    "# ---------- 4. ANÁLISIS DE GRUPO Y VISUALIZACIONES (REVISADO Y MEJORADO) ----------\n",
    "print(\"\\n--- 4. Generando Visualizaciones y Reportes Finales ---\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4.1 FUNCIONES DE VISUALIZACIÓN\n",
    "# ==============================================================================\n",
    "\n",
    "def plot_qc_visualizations(df, export_dir):\n",
    "    \"\"\"Genera y guarda gráficos para el control de calidad.\"\"\"\n",
    "    print(\"Generando gráficos de QC...\")\n",
    "    # Histograma de TPs eliminados\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['LeverageOutliersCount'], bins=20, kde=True)\n",
    "    plt.title(\"Distribución de Time-Points Eliminados por Sujeto (Scrubbing)\", fontsize=16)\n",
    "    plt.xlabel(\"Número de TPs Eliminados\")\n",
    "    plt.ylabel(\"Frecuencia (Nº de Sujetos)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(export_dir / \"fig_qc_scrubbing_histogram.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Violin plot de TPs eliminados por sitio\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    sns.violinplot(x='SiteID', y='LeverageOutliersCount', data=df)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Distribución de Time-Points Eliminados por Sitio\", fontsize=16)\n",
    "    plt.xlabel(\"ID del Sitio\")\n",
    "    plt.ylabel(\"Número de TPs Eliminados\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(export_dir / \"fig_qc_scrubbing_by_site.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_combat_effect(before_combat, after_combat, covariates, export_dir):\n",
    "    \"\"\"Visualiza el efecto de ComBat en la distribución de la conectividad.\"\"\"\n",
    "    print(\"Generando gráfico del efecto de ComBat...\")\n",
    "    df_list = []\n",
    "    n_samples = min(before_combat.size, 500000)\n",
    "    \n",
    "    # Datos antes de ComBat\n",
    "    df_before = pd.DataFrame(before_combat.T)\n",
    "    df_before['SiteID'] = covariates['SiteID'].values\n",
    "    df_before_long = pd.melt(df_before, id_vars='SiteID', var_name='feature_idx', value_name='Connectivity')\n",
    "    df_before_long['Estado'] = 'Antes de ComBat'\n",
    "    df_list.append(df_before_long.sample(n_samples))\n",
    "\n",
    "    # Datos después de ComBat\n",
    "    df_after = pd.DataFrame(after_combat.T)\n",
    "    df_after['SiteID'] = covariates['SiteID'].values\n",
    "    df_after_long = pd.melt(df_after, id_vars='SiteID', var_name='feature_idx', value_name='Connectivity')\n",
    "    df_after_long['Estado'] = 'Después de ComBat'\n",
    "    df_list.append(df_after_long.sample(n_samples))\n",
    "\n",
    "    plot_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    g = sns.FacetGrid(plot_df, col=\"SiteID\", hue=\"Estado\", col_wrap=7, height=2, aspect=1.5, palette=\"viridis\")\n",
    "    g.map(sns.kdeplot, \"Connectivity\", fill=True, alpha=0.6, common_norm=False)\n",
    "    g.add_legend()\n",
    "    g.fig.suptitle(\"Efecto de Armonización ComBat en la Distribución de Conectividad por Sitio\", y=1.03, fontsize=16)\n",
    "    g.set_axis_labels(\"Valor de Conectividad (r)\", \"Densidad\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
    "    plt.savefig(export_dir / \"fig_combat_effect_density.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def plot_connectivity_visualizations(conn_matrix, coords, export_dir):\n",
    "    \"\"\"Genera y guarda las principales visualizaciones de conectividad.\"\"\"\n",
    "    print(\"Generando gráficos de conectividad...\")\n",
    "    \n",
    "    # === CAMBIO v5.3: Se comenta la generación de la matriz de conectividad ===\n",
    "    # print(\"Generando matriz de conectividad promedio...\")\n",
    "    # display = nilearn_plotting.plot_matrix(conn_matrix, colorbar=True, vmax=0.8, vmin=-0.8,\n",
    "    #                                       title=\"Matriz de Conectividad Promedio (Armonizada)\")\n",
    "    # display.figure.savefig(export_dir / \"fig_mean_connectome_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "    # plt.close(display.figure)\n",
    "    # =========================================================================\n",
    "\n",
    "    # Conectoma 3D\n",
    "    if coords is not None:\n",
    "        print(\"Generando gráfico de conectoma 3D...\")\n",
    "        display = nilearn_plotting.plot_connectome(conn_matrix, coords, edge_threshold=\"98%\",\n",
    "                                                   node_size=10, display_mode='z',\n",
    "                                                   title=\"Conectoma 3D (2% más fuerte)\")\n",
    "        display.savefig(export_dir / \"fig_mean_connectome_3d.png\", dpi=300)\n",
    "        plt.close(display)\n",
    "    else:\n",
    "        print(\"No se generará el conectoma 3D por falta de coordenadas.\")\n",
    "\n",
    "\n",
    "def plot_dynamic_visualizations(df, n_states, covariates, export_dir):\n",
    "    print(\"Generando gráficos de conectividad dinámica...\")\n",
    "    \n",
    "    df_dyn = df[df['HasDynamicConnectivity']].copy()\n",
    "\n",
    "    # Hacer merge explícito por SubjectID para asegurar la alineación de datos\n",
    "    if 'Diagnosis' in covariates.columns and 'SubjectID' in covariates.columns:\n",
    "        df_dyn = df_dyn.merge(covariates[['SubjectID', 'Diagnosis']], on='SubjectID', how='left')\n",
    "\n",
    "    # Estados de conectividad a nivel de grupo\n",
    "    all_centroids_flat = [c for d in df_dyn['DynamicStates_Centroids'] if d is not None for c in d]\n",
    "    if len(all_centroids_flat) > n_states:\n",
    "        kmeans = KMeans(n_clusters=n_states, random_state=42, n_init='auto')\n",
    "        kmeans.fit(all_centroids_flat)\n",
    "        group_centroids_vec = kmeans.cluster_centers_\n",
    "\n",
    "        fig, axes = plt.subplots(1, n_states, figsize=(20, 4), facecolor='white')\n",
    "        fig.suptitle(\"Estados de Conectividad Dinámica a Nivel de Grupo\", fontsize=16)\n",
    "        for i, ax in enumerate(axes):\n",
    "            state_matrix = vec_to_sym_matrix(group_centroids_vec[i], diagonal=np.zeros(N_ROIS))\n",
    "            nilearn_plotting.plot_matrix(state_matrix, axes=ax, colorbar=True, vmax=0.8, vmin=-0.8)\n",
    "            ax.set_title(f\"Estado {i+1}\")\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.savefig(export_dir / \"fig_dynamic_connectivity_states.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    # Tasa de ocupancia por grupo\n",
    "    occupancy_data = []\n",
    "    for _, row in df_dyn.iterrows():\n",
    "        # Asegurarse que el sujeto tiene diagnóstico antes de procesar\n",
    "        if 'Diagnosis' in row and pd.notna(row['Diagnosis']) and row['DynamicStates_Occupancy'] is not None:\n",
    "            for i, occ in enumerate(row['DynamicStates_Occupancy']):\n",
    "                occupancy_data.append({'Diagnosis': row['Diagnosis'], 'State': f\"Estado {i+1}\", 'Occupancy': occ})\n",
    "\n",
    "    if occupancy_data:\n",
    "        occupancy_df = pd.DataFrame(occupancy_data)\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        sns.barplot(data=occupancy_df, x='State', y='Occupancy', hue='Diagnosis', errorbar='se')\n",
    "        plt.title(\"Tasa de Ocupancia Promedio por Estado y Grupo Diagnóstico\", fontsize=16)\n",
    "        plt.ylabel(\"Fracción de Tiempo\")\n",
    "        plt.xlabel(\"Estado de Conectividad\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(export_dir / \"fig_state_occupancy_by_group.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4.2 EJECUCIÓN DEL ANÁLISIS Y LAS VISUALIZACIONES\n",
    "# ==============================================================================\n",
    "\n",
    "# --- Visualización de QC primero (no depende de ComBat) ---\n",
    "plot_qc_visualizations(results_df, EXPORT_DIR)\n",
    "\n",
    "# --- Preparación y ejecución de la armonización con ComBat ---\n",
    "harmonized_features = np.array([])\n",
    "covariates_for_combat = pd.DataFrame() # Para usar en plots posteriores\n",
    "\n",
    "if NEUROCOMBAT_INSTALLED:\n",
    "    print(\"\\n--- 5. Armonizando Datos de Conectividad con ComBat ---\")\n",
    "    \n",
    "    # 1. Filtrar sujetos con conectomas válidos (no-NaN)\n",
    "    valid_subjects_df = results_df[results_df['StaticConnectivity'].apply(lambda x: not np.isnan(x).all())].copy()\n",
    "    \n",
    "    # 2. Excluir sitios con menos de 2 sujetos para evitar errores en ComBat\n",
    "    site_counts = valid_subjects_df['SiteID'].value_counts()\n",
    "    sites_to_exclude = site_counts[site_counts < 2].index.tolist()\n",
    "    \n",
    "    if sites_to_exclude:\n",
    "        print(f\"ADVERTENCIA: Excluyendo {len(sites_to_exclude)} sitios con < 2 sujetos para ComBat: {sites_to_exclude}\")\n",
    "        subjects_for_harmonization_df = valid_subjects_df[~valid_subjects_df['SiteID'].isin(sites_to_exclude)].copy()\n",
    "    else:\n",
    "        subjects_for_harmonization_df = valid_subjects_df.copy()\n",
    "\n",
    "    print(f\"Sujetos retenidos para armonización: {len(subjects_for_harmonization_df)}\")\n",
    "    \n",
    "    if len(subjects_for_harmonization_df) > 0:\n",
    "        # 3. Preparar la matriz de características (vectores de conectividad)\n",
    "        features_matrix = np.array([\n",
    "            sym_matrix_to_vec(m, discard_diagonal=True) \n",
    "            for m in subjects_for_harmonization_df['StaticConnectivity']\n",
    "        ]).T\n",
    "\n",
    "        # === CAMBIO v5.3: Crear covariables con EDAD REAL y diagnóstico ===\n",
    "        # Seleccionar las columnas necesarias del meta-data original\n",
    "        covariates_full = meta_df[['SubjectID', 'SiteID', 'Age', 'ResearchGroup']].rename(\n",
    "            columns={'ResearchGroup': 'Diagnosis'}\n",
    "        )\n",
    "        # Unir con el dataframe de sujetos válidos para asegurar la correspondencia\n",
    "        covariates_for_combat = subjects_for_harmonization_df[['SubjectID']].merge(\n",
    "            covariates_full, on='SubjectID', how='left'\n",
    "        )\n",
    "        # ===================================================================\n",
    "        \n",
    "        # Verificar si hay NaNs en las covariables (p. ej. edad faltante)\n",
    "        if covariates_for_combat.isnull().values.any():\n",
    "            print(\"ADVERTENCIA: Se encontraron valores nulos en las covariables. ComBat podría fallar.\")\n",
    "            print(covariates_for_combat[covariates_for_combat.isnull().any(axis=1)])\n",
    "\n",
    "        if features_matrix.shape[1] > 0:\n",
    "            try:\n",
    "                print(\"Ejecutando la armonización con ComBat en la muestra filtrada...\")\n",
    "                combat_results = neuroCombat(\n",
    "                    dat=features_matrix, \n",
    "                    covars=covariates_for_combat,\n",
    "                    batch_col='SiteID', \n",
    "                    categorical_cols=['Diagnosis'],\n",
    "                    # continuous_cols=['Age'] # Descomentar si quieres modelar la edad\n",
    "                )\n",
    "                harmonized_features = combat_results['data']\n",
    "                print(\"Armonización con ComBat completada con éxito.\")\n",
    "                plot_combat_effect(features_matrix, harmonized_features, covariates_for_combat, EXPORT_DIR)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"ERROR: Falló la armonización con ComBat. Error: {e}\")\n",
    "                harmonized_features = features_matrix # Usar datos sin armonizar si falla\n",
    "    else:\n",
    "        print(\"ADVERTENCIA: No hay suficientes sujetos para la armonización después de filtrar.\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nADVERTENCIA: Librería 'neuroCombat' no encontrada. Se omitirá la armonización.\")\n",
    "    # Usar los datos originales si ComBat no está instalado\n",
    "    valid_subjects_df = results_df[results_df['StaticConnectivity'].apply(lambda x: not np.isnan(x).all())].copy()\n",
    "    harmonized_features = np.array([sym_matrix_to_vec(d, discard_diagonal=True) \n",
    "                                     for d in valid_subjects_df['StaticConnectivity']]).T\n",
    "    # Crear covariables mínimas para los plots dinámicos\n",
    "    covariates_for_combat = valid_subjects_df[['SubjectID', 'SiteID']].merge(\n",
    "        meta_df[['SubjectID', 'ResearchGroup']].rename(columns={'ResearchGroup': 'Diagnosis'}),\n",
    "        on='SubjectID', how='left'\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Análisis final y visualizaciones de conectividad ---\n",
    "if harmonized_features.size > 0:\n",
    "    print(\"\\nCalculando conectoma promedio y generando visualizaciones finales...\")\n",
    "    \n",
    "    # Calcular conectoma promedio de forma robusta (ignorando NaNs)\n",
    "    mean_vec = np.nanmean(harmonized_features, axis=1)\n",
    "\n",
    "    if np.isnan(mean_vec).all():\n",
    "        print(\"ERROR: No se pudo calcular el conectoma promedio. El vector resultante es todo NaN.\")\n",
    "    else:\n",
    "        mean_connectome_matrix = vec_to_sym_matrix(mean_vec, diagonal=np.zeros(N_ROIS))\n",
    "        print(f\"Conectoma promedio calculado. Min: {np.nanmin(mean_connectome_matrix):.4f}, Max: {np.nanmax(mean_connectome_matrix):.4f}\")\n",
    "        \n",
    "        # Guardar resultados\n",
    "        np.save(EXPORT_DIR / \"harmonized_connectivity_vectors.npy\", harmonized_features)\n",
    "        np.save(EXPORT_DIR / \"mean_harmonized_connectome.npy\", mean_connectome_matrix)\n",
    "        \n",
    "        # Generar visualizaciones de conectividad\n",
    "        plot_connectivity_visualizations(mean_connectome_matrix, schaefer_coords, EXPORT_DIR)\n",
    "\n",
    "    # Generar visualizaciones dinámicas (usando todos los datos, no solo los armonizados)\n",
    "    plot_dynamic_visualizations(results_df, N_CONNECTIVITY_STATES, covariates_for_combat, EXPORT_DIR)\n",
    "\n",
    "else:\n",
    "    print(\"No se generaron visualizaciones de conectividad de grupo porque no había datos válidos.\")\n",
    "\n",
    "\n",
    "print(\"\\n--- ¡Pipeline Finalizado! ---\")\n",
    "print(f\"Resultados y gráficos guardados en: {EXPORT_DIR}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
